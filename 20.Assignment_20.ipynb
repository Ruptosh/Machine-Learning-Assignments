{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2aa57f2",
   "metadata": {},
   "source": [
    "# Assignment 20 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111120c6",
   "metadata": {},
   "source": [
    "##### 1. What is the underlying concept of Support Vector Machines ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c6ff3",
   "metadata": {},
   "source": [
    "**Ans:-** The underlying concept of Support Vector Machines (SVMs) is to find the best possible decision boundary that separates two classes of data points. SVMs aim to find the hyperplane that maximizes the margin between the two classes, i.e., the distance between the closest data points of each class to the hyperplane. SVMs can also handle non-linearly separable data by transforming the input data into a higher-dimensional space, where a linear boundary can be found. SVMs aim to minimize the classification error and maximize the margin, which provides a good generalization performance. SVMs have found extensive use in a wide range of applications such as image classification, text classification, bioinformatics, and financial data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae857d4",
   "metadata": {},
   "source": [
    "##### 2. What is the concept of a support vector ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764f840d",
   "metadata": {},
   "source": [
    "**Ans:-** In Support Vector Machines (SVM), a support vector is a data point that defines the boundary between classes. These data points lie closest to the hyperplane, the decision boundary that separates the classes in the feature space, and therefore, they have the greatest impact on the SVM model's accuracy. In other words, these support vectors are the critical elements in SVM that allow it to create the best decision boundary possible by maximizing the margin between classes while minimizing the classification error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981ac1e",
   "metadata": {},
   "source": [
    "##### 3. When using SVMs, why is it necessary to scale the inputs ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ffdf8d",
   "metadata": {},
   "source": [
    "**Ans:-** It is necessary to scale the inputs when using SVMs because SVMs rely on calculating distances between data points, specifically the distance between support vectors and the hyperplane. If the features have different scales, then the distances calculated will be dominated by the features with larger scales, and the importance of features with smaller scales will be minimized. As a result, scaling the features ensures that each feature is given equal importance in the distance calculations and the SVMs are optimized for all features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2a64",
   "metadata": {},
   "source": [
    "##### 4. When an SVM classifier classifies a case, can it output a confidence score? What about a percentage chance ? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a706394",
   "metadata": {},
   "source": [
    "**Ans:-** Yes, an SVM classifier can output a confidence score or a percentage chance, depending on the method used for classification.\n",
    "\n",
    "One common method is to use the distance between the input point and the decision boundary (i.e., the margin) as a confidence score. The larger the margin, the more confident the classifier is in its prediction. In this case, the confidence score can be interpreted as the distance to the decision boundary.\n",
    "\n",
    "Another method is to use probabilistic models, such as Platt scaling or isotonic regression, to estimate the probability of a given input belonging to each class. In this case, the classifier can output a percentage chance for each class.\n",
    "\n",
    "However, it's important to note that not all SVM implementations support probability estimates, and in some cases, the confidence score may be used as a proxy for probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2162e",
   "metadata": {},
   "source": [
    "##### 5. Should you train a model on a training set with millions of instances and hundreds of features using the primal or dual form of the SVM problem ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b91a6",
   "metadata": {},
   "source": [
    "**Ans:-** In general, if the number of instances is much greater than the number of features, it is recommended to use the primal form of the SVM problem. On the other hand, if the number of features is much greater than the number of instances, it is recommended to use the dual form. However, there is no hard and fast rule and the optimal choice may depend on various factors such as the computational resources available and the specific characteristics of the data. In practice, it may be necessary to experiment with both forms and choose the one that performs better on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96163dd",
   "metadata": {},
   "source": [
    "##### 6. Let's say you've used an RBF kernel to train an SVM classifier, but it appears to underfit the training collection. Is it better to raise or lower (gamma)? What about the letter C ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6700f0",
   "metadata": {},
   "source": [
    "**Ans:-** If an SVM classifier trained with an RBF kernel appears to underfit the training set, it is typically necessary to raise gamma. This would increase the decision boundary's curvature, allowing it to fit the data more tightly.\n",
    "\n",
    "On the other hand, if the SVM classifier overfits the training set, it may be necessary to decrease gamma to reduce the decision boundary's curvature and improve generalization. This is also known as regularization, which decreases the model's sensitivity to the training data and prevents it from overfitting.\n",
    "\n",
    "In terms of the C parameter, increasing it would reduce regularization and allow the classifier to fit the data more closely. Conversely, decreasing C would increase regularization and prevent overfitting. Therefore, if the SVM classifier is underfitting, increasing gamma and decreasing C could be beneficial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b649e",
   "metadata": {},
   "source": [
    "##### 7. To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, how should the QP parameters (H, f, A, and b) be set ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1092653f",
   "metadata": {},
   "source": [
    "**Ans:-** To solve the soft margin linear SVM classifier problem with an off-the-shelf QP solver, the QP parameters (H, f, A, and b) should be set as follows:\n",
    "\n",
    "H: A (m+n) x (m+n) positive definite matrix where the top-left corner is the identity matrix (m is the number of training instances, and n is the number of features). The other entries should be zero or correspond to the kernel matrix.\n",
    "\n",
    "f: A (m+n) dimensional vector initialized to -1.\n",
    "\n",
    "A: An (m x (m+n)) matrix containing the horizontal stack of (1) the identity matrix multiplied by C and (2) an (m x n) matrix containing the feature vectors multiplied by -y.\n",
    "\n",
    "b: An m-dimensional vector initialized to 0.\n",
    "\n",
    "Here, y is the target class (1 or -1), and C is the hyperparameter that controls the balance between margin violations and keeping the margin as large as possible. The choice of C is typically determined using cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54020cf8",
   "metadata": {},
   "source": [
    "##### 8. On a linearly separable dataset, train a LinearSVC. Then, using the same dataset, train an SVC and an SGDClassifier. See if you can get them to make a model that is similar to yours ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f17a6d2",
   "metadata": {},
   "source": [
    "**Ans:-** Here's an example of training a LinearSVC, SVC, and SGDClassifier on a linearly separable dataset and comparing their results:\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate linearly separable dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=2, n_informative=2, n_redundant=0,\n",
    "                            n_clusters_per_class=1, random_state=42, class_sep=2.0)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a LinearSVC\n",
    "linear_svc = LinearSVC(random_state=42)\n",
    "linear_svc.fit(X_train, y_train)\n",
    "y_pred_linear_svc = linear_svc.predict(X_test)\n",
    "print(f\"LinearSVC accuracy: {accuracy_score(y_test, y_pred_linear_svc)}\")\n",
    "\n",
    "# Train an SVC\n",
    "svc = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "print(f\"SVC accuracy: {accuracy_score(y_test, y_pred_svc)}\")\n",
    "\n",
    "# Train an SGDClassifier\n",
    "sgd = SGDClassifier(loss='hinge', alpha=0.01, random_state=42)\n",
    "sgd.fit(X_train, y_train)\n",
    "y_pred_sgd = sgd.predict(X_test)\n",
    "print(f\"SGDClassifier accuracy: {accuracy_score(y_test, y_pred_sgd)}\")\n",
    "\n",
    "In this example, we generate a linearly separable dataset with 2 features and 1000 samples. We split the dataset into training and testing sets, and then train a LinearSVC, SVC with a linear kernel, and SGDClassifier with hinge loss. We then compare the accuracy scores of the three models on the testing set.\n",
    "\n",
    "The results may vary each time you run the code due to the random seed. But generally, the LinearSVC and SVC models should have similar accuracy scores since they both use the same linear kernel. The SGDClassifier may have slightly lower accuracy due to the stochastic nature of its optimization algorithm.\n",
    "\n",
    "Overall, the LinearSVC and SVC models should have similar results in this case, but the SGDClassifier may perform slightly worse due to its stochastic nature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db681d1",
   "metadata": {},
   "source": [
    "##### 9. On the MNIST dataset, train an SVM classifier. You'll need to use one-versus-the-rest to assign all 10 digits because SVM classifiers are binary classifiers. To accelerate up the process, you might want to tune the hyperparameters using small validation sets. What level of precision can you achieve ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f76140",
   "metadata": {},
   "source": [
    "**Ans:-** Here's an example code to train an SVM classifier on the MNIST dataset using one-versus-the-rest approach and hyperparameter tuning:\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X, y = mnist['data'], mnist['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "svm_clf = SVC()\n",
    "grid_search = GridSearchCV(svm_clf, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Train SVM classifier with best hyperparameters\n",
    "svm_clf = SVC(C=grid_search.best_params_['C'], kernel=grid_search.best_params_['kernel'])\n",
    "svm_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = svm_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "The code splits the MNIST dataset into training and test sets, performs a grid search for the best hyperparameters using 5-fold cross-validation on the training set, trains the SVM classifier on the full training set with the best hyperparameters, and evaluates its accuracy on the test set.\n",
    "\n",
    "With this approach, we can achieve an accuracy of around 0.98, which is quite good considering the simplicity of the model. However, there are more sophisticated approaches, such as deep neural networks, that can achieve even higher accuracy on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b686929",
   "metadata": {},
   "source": [
    "##### 10. On the California housing dataset, train an SVM regressor ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ee0c58",
   "metadata": {},
   "source": [
    "**Ans:-** Here's an example of training an SVM regressor on the California housing dataset:\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the California housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(housing.data, housing.target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train an SVM regressor\n",
    "svm_reg = SVR(kernel='linear')\n",
    "svm_reg.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "y_pred = svm_reg.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: \", mse)\n",
    "\n",
    "In this example, we're using a linear kernel for the SVM regressor. We split the data into training and testing sets, trained the model on the training set, and evaluated its performance on the testing set using mean squared error (MSE) as the evaluation metric.\n",
    "\n",
    "Note that there are many other hyperparameters that can be tuned for SVM regression, such as the regularization parameter C and the kernel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25cae96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
